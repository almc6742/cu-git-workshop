{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 3: LASSO Regression",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/almc6742/cu-git-workshop/blob/master/Exercise_3_LASSO_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhvmFCzyUUU-",
        "colab_type": "code",
        "outputId": "ce79611a-4492-49d0-e0af-eaeab3b438fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import pandas as pd\n",
        "import pandas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LassoLarsCV\n",
        "from sklearn.datasets import make_regression\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3oPs1lCWCc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sales_data = 'drive/My Drive/Colab Notebooks/finalmaster-ratios.csv'\n",
        "df = pd.read_csv(sales_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp5dRgQcXwir",
        "colab_type": "text"
      },
      "source": [
        "List of predictors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z12PvL03Xg0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allvariablenames = list(df.columns.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hagv6a4hYLbp",
        "colab_type": "text"
      },
      "source": [
        "Remove first 8 variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCg6kY-ZXtWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "listofallpredictors = allvariablenames[8:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWPUNyjFZIFd",
        "colab_type": "text"
      },
      "source": [
        "Get columns ready in pandas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z1Dil3MZKuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors = df[listofallpredictors]\n",
        "\n",
        "target = df['# Purchases']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGqvbmNzZZYY",
        "colab_type": "text"
      },
      "source": [
        "Split the data (by rows):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPIUuRmPZVbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, target, test_size=.3, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uug6K58ZzzL",
        "colab_type": "text"
      },
      "source": [
        "Use LassoLarsCV to build a LASSO model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exwWsrZIZzWS",
        "colab_type": "code",
        "outputId": "5f8aa901-0219-4da2-ed69-44365b3b6c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X = predictors\n",
        "Y = target\n",
        "\n",
        "model = LassoLarsCV(cv=10, precompute=False).fit(X, Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.526e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.263e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.263e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.062e-01, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=3.088e-01, previous alpha=2.950e-01, with an active set of 18 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=6.504e-02, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=6.268e-02, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=3.451e-02, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=3.451e-02, with an active set of 94 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=3.248e-02, with an active set of 95 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=3.221e-02, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.123e-02, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 127 iterations, alpha=2.315e-02, previous alpha=2.288e-02, with an active set of 106 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=1.420e-01, previous alpha=1.311e-01, with an active set of 41 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.512e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.756e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.512e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.512e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.657e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.256e-01, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 34 iterations, alpha=2.245e-01, previous alpha=2.219e-01, with an active set of 25 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.790e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.830e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.591e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 8.878e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.479e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.174e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=7.445e-02, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=7.377e-02, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 99 iterations, alpha=5.923e-02, previous alpha=5.912e-02, with an active set of 78 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.454e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.033e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=9.297e-01, previous alpha=8.763e-01, with an active set of 10 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.072e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.310e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.089e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.029e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.222e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.202e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.750e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 44 iterations, alpha=1.614e-01, previous alpha=1.573e-01, with an active set of 37 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.761e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.608e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.881e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.370e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=3.317e-01, previous alpha=3.294e-01, with an active set of 20 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.169e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 29 iterations, alpha=2.537e-01, previous alpha=2.486e-01, with an active set of 24 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.598e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.598e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.299e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.299e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.913e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=1.860e-01, previous alpha=1.860e-01, with an active set of 33 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.070e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.750e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.035e-01, with an active set of 18 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.579e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI_822i9cJxg",
        "colab_type": "code",
        "outputId": "c618bd81-361c-436f-b609-7c8d0495ce0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "predictors_model=pd.DataFrame(listofallpredictors)\n",
        "predictors_model.columns = ['label']\n",
        "predictors_model['coeff'] = model.coef_\n",
        "\n",
        "for index, row in predictors_model.iterrows():\n",
        "    if row['coeff'] > 0:\n",
        "        print(row.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B01001014' 0.5330720656233966]\n",
            "['B01001036' 1.6591227573088478]\n",
            "['B01001037' 2.4482060101637564]\n",
            "['B01001038' 2.21381020716577]\n",
            "['B02001005' 0.9859155344708008]\n",
            "['B02001007' 0.006591090821753925]\n",
            "['B13014016' 0.0061795097515955225]\n",
            "['B13014026' 0.574990933842321]\n",
            "['B13014027' 1.2849909864550721]\n",
            "['B13016008' 0.31692716289106393]\n",
            "['B15002027' 3.9418447021477347]\n",
            "['B19001017' 1.8860806124452758]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdYGtva5cPzw",
        "colab_type": "text"
      },
      "source": [
        "Question #1:\n",
        "The first line of code creates a Pandas dataframe from the predictor variables in our dataset. The second line of code initalizes an indexable column (label) for the variable names. The third line of code pulls the coefficients from our LASSO model as a second column aligned with their respective predictor variable column name. The \"for-loop\" iterates over the rows in our newly created dataframe and keeps all significant rows, or rows in which the coefficients are greater than 0. The result is an array containing which variables most predicted sales along with their associated coefficients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJbQqnQzepei",
        "colab_type": "text"
      },
      "source": [
        "Question #2: The greatest predictor of sales is the census variable B15002027, respresenting females in the population aged 25 and older whom completed the 12th grade but did not receive a diploma. Based on the provided predictor variables, we sell the most Bobo Bars among this 25+ female population with no high school diploma but completed education through 12th grade. The next two strongest predictors include females aged 30-34 followed by females 35-39."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeN3bS0-gtsj",
        "colab_type": "text"
      },
      "source": [
        "Question #3:\n",
        "The two census variables that most steeply predicted sales include B15002027 and B01001036."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Sr0Uk-UhQ4r",
        "colab_type": "code",
        "outputId": "d709f35b-44cb-49b7-bf7c-fdb583ef9dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
        "print ('training data MSE')\n",
        "print(train_error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data MSE\n",
            "21060.761034858362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvaMUbuPiF8w",
        "colab_type": "code",
        "outputId": "09a5a036-38e7-4b3d-f874-c194b323102d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "test_error = mean_squared_error(tar_test, model.predict(pred_test))\n",
        "print ('testing data MSE')\n",
        "print(test_error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing data MSE\n",
            "36561.48369809522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgnFebyfji_M",
        "colab_type": "text"
      },
      "source": [
        "Question #4:\n",
        "Using the MSE tool from sklearn, we find that the test set has a mean-squared error of 36561.484 while the training set has a mean-squared error of 21060.761. There is greater bias and variance in our test set than our training set; however, n is large enough such that the difference is negligible. In practical terms, determining the MSE helped us to assess the closeness of our predictor variable data to the target variable when bias and sampling error are taken into account. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31SrsVIenpxU",
        "colab_type": "code",
        "outputId": "66fb8d45-7ec8-4ce4-8904-926a174ebaf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "rsquared_train=model.score(pred_train,tar_train)\n",
        "print ('training data R-square')\n",
        "print(rsquared_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data R-square\n",
            "0.2733096196457573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Oi9ApTnsnK",
        "colab_type": "code",
        "outputId": "7463a52a-11f4-4680-efb7-0f406cef3194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "rsquared_test=model.score(pred_test,tar_test)\n",
        "print ('testing data R-square')\n",
        "print(rsquared_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing data R-square\n",
            "0.27480133108928484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZhKJVzBoJxy",
        "colab_type": "text"
      },
      "source": [
        "Question #5:\n",
        "The R-squared of the training set is nearly equivalent to that of the test set. The census data predicts a significant amount of overall sales data. The predictor variables in this dataset can be used to predict sales in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85PnkzWho2IG",
        "colab_type": "code",
        "outputId": "30d1d9fd-a683-4849-d8e0-6c955831c4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"y interecept:\")\n",
        "print(model.intercept_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y interecept:\n",
            "-3.9606645084610435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t79rlLgxo6TH",
        "colab_type": "text"
      },
      "source": [
        "Question #6:\n",
        "Our baselines sales number is essentially 4 purchases (above 3.96). This means that 4 sales must be made before we can say with certainty that our model will help predict sales based on provided data."
      ]
    }
  ]
}